# Journal Project

My journal project to log daily work, struggles, and intentions. 
Designed for developers and learners to reflect and track progress.

This repository contains a GitHub Actions workflow to build, test, push, and deploy a Dockerized FastAPI application to Amazon EKS, along with infrastructure provisioning using Terraform.

## What this pipeline does

1. **Build and test Docker image**  
   - Checks out the code  
   - Builds the Docker image  
   - Runs a container locally in the GitHub runner  
   - Sends a test request to verify the app is running  
   - Cleans up the container

2. **Push Docker image to Amazon ECR**  
   - Logs into AWS ECR  
   - Builds, tags, and pushes the Docker image with the commit SHA as the tag  
   - Saves the image URI as an artifact for downstream jobs

3. **Provision AWS infrastructure with Terraform**  
   - Runs `terraform init` and `terraform apply` inside the `infra/` folder  
   - Applies variables like DB username, password, and access CIDR from GitHub Secrets  
   - Outputs RDS endpoint, EKS cluster name, and region

4. **Configure kubectl and deploy the app to EKS**  
   - Updates kubeconfig with the new EKS cluster details  
   - Downloads the Docker image URI artifact  
   - Substitutes the image URI and RDS endpoint in Kubernetes manifests  
   - Creates Kubernetes secrets for DB credentials  
   - Applies the Kubernetes manifests (ConfigMap, Deployment, Service)

5. **Optional cleanup step**  
   - Runs `terraform destroy` at the end if the job finishes (can be disabled)

## Prerequisites

- AWS account with permissions to manage EKS, EC2, RDS, ECR, and IAM  
- RDS PostgreSQL database (the pipeline provisions RDS, but the user still needs to configure the database server manually, e.g., set up schemas, users, etc.)  
- GitHub account with access to the API repository
- GitHub repository with the following secrets configured:

| Secret Name          | Description                          |
|----------------------|------------------------------------|
| `AWS_ACCESS_KEY_ID`   | AWS access key                     |
| `AWS_SECRET_ACCESS_KEY` | AWS secret key                   |
| `AWS_REGION`          | AWS region (e.g., `us-east-1`)     |
| `DB_USER`             | Database username for Terraform     |
| `DB_PASS`             | Database password for Terraform     |
| `PRINCIPAL_ARN`       | IAM principal ARN for Terraform     |
| `ACCESS_CIDR`         | CIDR block allowed to access RDS    |
| `DB_USER_REPLACE`     | Database username for Kubernetes secret |
| `DB_PASS_REPLACE`     | Database password for Kubernetes secret |

# Terraform Backend Setup

You need to create an **S3 bucket** to store the Terraform state remotely and enable state locking for concurrency safety.
View configuration in infra/providers.tf

---

## How to use

1. Push your code changes to the `main` branch or open a pull request targeting `main`.  
2. The GitHub Actions workflow will automatically run the pipeline.  
3. The app will be deployed to the EKS cluster and accessible via the configured service.  
4. **Manually configure your RDS PostgreSQL database**
   - SSM into the database_editor ec2 instance
```bash
sudo apt update
sudo apt install postgresql-client -y
psql -h <RDS-ENDPOINT> -U <USERNAME> -d <DBNAME>
```
   - Create your database table in postgres
```sql
CREATE TABLE entries (
   id TEXT PRIMARY KEY,
   data JSONB NOT NULL,
   created_at TIMESTAMPTZ NOT NULL,
   updated_at TIMESTAMPTZ NOT NULL
);
```

---

## Notes

- The pipeline **installs Terraform and kubectl dynamically** on the runner.  
- The `terraform destroy` step runs at the end of the deploy job unconditionally (`if: always()`), so your infrastructure will be deleted after deployment unless you remove or comment out that step.  
- The Kubernetes manifests are templated using `sed` in the workflow â€” be careful to keep placeholders consistent (`REPLACE_ME_IMAGE` and `DB_ENDPOINT`).  
- Secrets management is done via GitHub Secrets and Kubernetes Secrets.

---

If you want to **retain the infrastructure**, remove or disable the `terraform destroy` step from the workflow.

---

### Example Entry
```json
{
  "work": "Worked on FastAPI routes",
  "struggle": "Entries not created",
  "intention": "Fix configuration"
}
```
## Development Tasks

### API Implementation

1. Endpoint in `journal_router.py` have been updated:
   - GET /entries - List all journal entries
   - GET /entries/{entry_id} - Get single entry
   - DELETE /entries/{entry_id} - Delete specific entry

### Logging Setup

1. Basic console logging in `main.py`:
   - Configure basic logging
   - Set logging level to INFO
   - Add console handler

### Data Model Improvements

1. Entry model in `models/entry.py` has been added to `services/entry_service.py`:
   - Added basic field validation rules
   - Added input data sanitization
   - Added schema version tracking

### Development Environment

1. Configure cloud provider CLI in `.devcontainer/devcontainer.json`:
   - AWSCLI configured along with env variables


### Data Schema

The journal entry data model is structured as follows:

| Field       | Type      | Description                                | Validation                   |
|-------------|-----------|--------------------------------------------|------------------------------|
| id          | string    | Unique identifier for the entry (UUID)     | Auto-generated UUID          |
| work        | string    | What did you work on today?                | Required, max 256 characters |
| struggle    | string    | What's one thing you struggled with today? | Required, max 256 characters |
| intention   | string    | What will you study/work on tomorrow?      | Required, max 256 characters |
| created_at  | datetime  | Timestamp when the entry was created       | Auto-generated UTC timestamp |
| updated_at  | datetime  | Timestamp when the entry was last updated  | Auto-updated UTC timestamp   |

All text fields sanitizatized to prevent injection attacks and ensure data quality. The schema includes version tracking to handle potential future changes to the data structure.

### API Endpoints

1. **GetEntries:** Returns a JSON list of all journal entries - IMPLEMENTED
2. **GetEntry:** Returns a specific journal entry by ID - IMPLEMENTED
3. **DeleteEntry:** Removes a specific journal entry - IMPLEMENTED
4. **CreateEntry:** Creates a new journal entry - IMPLEMENTED
5. **UpdateEntry:** Updates an existing journal entry - IMPLEMENTED
6. **DeleteAllEntries:** Removes all journal entries - IMPLEMENTED